# ğŸš€ SummarEaseAI v2.0

**SummarEaseAI v2.0** is an AI-powered chatbot that intelligently summarizes Wikipedia articles using state-of-the-art machine learning technologies. It combines **TensorFlow neural networks** for intent classification, **ğŸ¤— Hugging Face Transformers** for local AI capabilities, **LangChain** for prompt orchestration, and **OpenAI's GPT** models for high-quality summarizationâ€”all wrapped in a beautiful Streamlit interface.

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—_Transformers-4.35+-yellow.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

</div>

---

## ğŸ¯ Currently Working Features âœ…

### ğŸ§  **Intent Recognition**
- **TensorFlow Neural Network**: âœ… **WORKING** - Custom Bidirectional LSTM model for intent classification
- **Keyword-based Fallback**: âœ… **WORKING** - Reliable backup intent classification system
- **9 Intent Categories**: âœ… **WORKING** - History, Science, Biography, Technology, Arts (includes Music), Sports, Politics, Geography, General
- **Real-time Confidence Scoring**: âœ… **WORKING** - Interactive gauges showing prediction confidence

### ğŸ¤– **Multi-Source Intelligence**
- **ğŸ¤– Multi-Source Agent**: âœ… **WORKING** - Advanced multi-article synthesis with LangChain agents
- **QueryEnhancementAgent**: âœ… **WORKING** - Intelligent query refinement and expansion
- **ArticleSelectionAgent**: âœ… **WORKING** - Smart Wikipedia article selection from search results
- **Wikipedia Content Sanitization**: âœ… **WORKING** - Handles curly braces and wiki markup safely
- **Cost Control**: âœ… **WORKING** - BALANCED/MINIMAL/COMPREHENSIVE modes for API usage
- **Comprehensive Synthesis**: âœ… **WORKING** - Combines multiple Wikipedia articles into coherent summaries

### âœ‚ï¸ **Summarization Engines**
- **OpenAI + LangChain**: âœ… **WORKING** - High-quality cloud-based summarization
- **Multi-Source Synthesis**: âœ… **WORKING** - Combines multiple articles with intelligent agents
- **Length Control**: âœ… **WORKING** - Customizable summary length (10-100 lines)
- **Intent-Aware Processing**: âœ… **WORKING** - Context-based summarization adaptation

### ğŸ“š **Wikipedia Integration**
- **Smart Search**: âœ… **WORKING** - Automatic fallback to search when direct articles aren't found
- **Disambiguation Handling**: âœ… **WORKING** - Intelligent resolution of ambiguous Wikipedia pages
- **Content Sanitization**: âœ… **WORKING** - Handles Wikipedia markup and special characters
- **Multi-Article Support**: âœ… **WORKING** - Fetch and process multiple related articles

### ğŸ¨ **Modern UI/UX**
- **5-Tab Interface**: âœ… **WORKING** - Summarize, Intent Analysis, Semantic Search, Model Comparison, Analytics
- **Real-time Visualizations**: âœ… **WORKING** - Interactive charts and gauges using Plotly
- **Model Status Indicators**: âœ… **WORKING** - Visual indicators for API and model availability
- **Progressive Enhancement**: âœ… **WORKING** - Graceful degradation when services are unavailable
- **Responsive Design**: âœ… **WORKING** - Beautiful interface with custom CSS styling

---

## ğŸš§ Features Under Development / Testing ğŸ§ª

### ğŸ¤— **Local AI with Hugging Face** - NOW UNDER TEST
- **Local Summarization**: ğŸ§ª **UNDER TEST** - Run AI models offline without API dependencies
- **Multiple Models**: ğŸ§ª **UNDER TEST** - BART, T5, DistilBART, Pegasus for different use cases
- **GPU Acceleration**: ğŸ§ª **UNDER TEST** - Automatic CUDA detection for faster inference

### ğŸ” **Semantic Search** - NOW UNDER TEST
- **Meaning-Based Search**: ğŸ§ª **UNDER TEST** - Find articles by semantic similarity, not just keywords
- **Sentence Transformers**: ğŸ§ª **UNDER TEST** - Convert text to 384-dimensional meaning vectors
- **Cosine Similarity**: ğŸ§ª **UNDER TEST** - Mathematical comparison of text meanings

### ğŸ§  **BERT Intent Classification** - NOW UNDER TEST
- **ğŸ¤— BERT Transformer**: ğŸ§ª **UNDER TEST** - Pre-trained BERT model fine-tuned for intent detection
- **Model Comparison**: ğŸ§ª **UNDER TEST** - Side-by-side comparison of TensorFlow vs BERT performance

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Status | Purpose |
|-----------|------------|--------|---------|
| **Frontend** | Streamlit | âœ… **WORKING** | Interactive web interface |
| **Backend** | Flask + CORS | âœ… **WORKING** | RESTful API server |
| **Intent Classification** | TensorFlow + Keywords | âœ… **WORKING** | Dual ML approach |
| **Multi-Source Agents** | LangChain + OpenAI | âœ… **WORKING** | Intelligent article synthesis |
| **Summarization** | LangChain + OpenAI | âœ… **WORKING** | Cloud-based summarization |
| **Local AI** | ğŸ¤— Transformers | ğŸ§ª **UNDER TEST** | Local model inference |
| **Semantic Search** | ğŸ¤— Sentence Transformers | ğŸ§ª **UNDER TEST** | Meaning-based retrieval |
| **Data Source** | Wikipedia API | âœ… **WORKING** | Article content |
| **Visualization** | Plotly | âœ… **WORKING** | Interactive charts |

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- OpenAI API key (required for current working features)
- 4GB+ RAM (recommended)
- Git

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/SummarEaseAI.git
cd SummarEaseAI
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Environment Setup
```bash
cp env.template .env
# Edit .env and add your OpenAI API key
```

### 4. Train TensorFlow Model
```bash
cd tensorflow_models
python train_model.py
cd ..
```

### 5. Start the Application
```bash
# Terminal 1 - Backend API
cd backend && python api_simple.py

# Terminal 2 - Frontend (in new terminal)
streamlit run app.py
```

### 6. Quick Start Script
```bash
# Alternative: Use the quick start script
python quick_start.py
```

### 7. Access the Application
Open your browser and navigate to `http://localhost:8501`

---

## ğŸ“Š Current Architecture

```mermaid
graph TD
    A[User Input] --> B[Streamlit Frontend v2.0]
    B --> C[Flask API Backend]
    C --> D[Intent Classifier]
    D --> E[TensorFlow LSTM âœ…]
    D --> F[Keyword Fallback âœ…]
    C --> G[Multi-Source Agent âœ…]
    G --> H[QueryEnhancementAgent âœ…]
    G --> I[ArticleSelectionAgent âœ…]
    C --> J[OpenAI + LangChain âœ…]
    C --> K[Wikipedia Fetcher âœ…]
    K --> L[Wikipedia API âœ…]
    J --> M[Cloud Summary âœ…]
    H --> N[Enhanced Queries âœ…]
    I --> O[Selected Articles âœ…]
    M --> B
    N --> K
    O --> J
    
    %% Under Test Features
    C --> P[ğŸ§ª Local HF Models]
    C --> Q[ğŸ§ª Semantic Search]
    C --> R[ğŸ§ª BERT Intent]
    P --> S[ğŸ§ª Local Summary]
    Q --> T[ğŸ§ª Vector Search]
    R --> U[ğŸ§ª BERT Prediction]
```

---

## ğŸ”§ Detailed Usage

### Working API Endpoints âœ…

#### Core Endpoints
- `GET /` - API status and feature availability âœ…
- `GET /health` - Health check âœ…
- `GET /status` - Detailed system status âœ…

#### Intent Classification
- `POST /predict_intent` - TensorFlow LSTM + keyword fallback âœ…

#### Summarization
- `POST /summarize` - OpenAI + LangChain summarization âœ…
- `POST /summarize_multi_source` - Multi-source agent synthesis âœ…
- `POST /summarize_agentic` - Enhanced agentic summarization âœ…

#### Wikipedia Integration
- `POST /search_wikipedia` - Smart Wikipedia search âœ…

### Under Test Endpoints ğŸ§ª

#### Advanced Features
- `POST /predict_intent_bert` - ğŸ§ª BERT intent prediction
- `POST /compare_models` - ğŸ§ª Compare TensorFlow vs BERT
- `POST /summarize_local` - ğŸ§ª Local Hugging Face summarization
- `POST /semantic_search` - ğŸ§ª Semantic Wikipedia search

### Usage Examples

#### 1. Multi-Source Agent (Working âœ…)
```python
import requests

response = requests.post('http://localhost:5000/summarize_multi_source', json={
    'query': 'Who were the Beatles?',
    'max_lines': 30,
    'use_intent': True
})

result = response.json()
print(f"Summary: {result['summary']}")
print(f"Articles used: {result['wikipedia_pages_used']}")
print(f"Agent powered: {result['agent_powered']}")
```

#### 2. Intent Classification (Working âœ…)
```python
response = requests.post('http://localhost:5000/predict_intent', json={
    'text': 'Tell me about quantum physics'
})

result = response.json()
print(f"Intent: {result['predicted_intent']}")
print(f"Confidence: {result['confidence']}")
print(f"Model: {result['model_used']}")
```

#### 3. OpenAI Summarization (Working âœ…)
```python
response = requests.post('http://localhost:5000/summarize', json={
    'query': 'Apollo 11 moon landing',
    'max_lines': 25
})

result = response.json()
print(f"Summary: {result['summary']}")
print(f"Method: {result['method']}")
```

---

## ğŸ§ª Test Queries for Working Features

### Multi-Source Agent Examples âœ…
- **"Who were the Beatles?"** â†’ Synthesizes band info, discography, and musical style
- **"What is quantum mechanics?"** â†’ Combines physics articles and applications
- **"Tell me about World War II"** â†’ Merges historical events, battles, and outcomes

### Intent Classification Test Queries âœ…
- **History**: "What happened during the Apollo 11 mission?"
- **Science**: "Explain how photosynthesis works"
- **Biography**: "Tell me about Marie Curie's discoveries"
- **Technology**: "How do neural networks function?"
- **Arts (Music)**: "Who were the Beatles?" 
- **Geography**: "Where are the Himalayas located?"

### Regular Summarization Examples âœ…
- **"Artificial Intelligence"** â†’ Comprehensive AI overview
- **"Climate Change"** â†’ Environmental science summary
- **"Renaissance Art"** â†’ Cultural and artistic movements

---

## ğŸ“ˆ Current Performance Metrics

### TensorFlow LSTM Intent Classifier âœ…
- **Training Accuracy**: ~95%
- **Validation Accuracy**: ~92%
- **Model Size**: ~2.5MB
- **Inference Time**: <100ms per query
- **Categories**: 9 distinct intent classes (History, Science, Biography, Technology, Arts, Sports, Politics, Geography, General)
- **Fallback**: Keyword-based system for reliability

### Multi-Source Agent System âœ…
- **Articles per Query**: 1-3 (configurable)
- **Cost Modes**: MINIMAL, BALANCED, COMPREHENSIVE
- **Agent Types**: QueryEnhancement, ArticleSelection
- **Response Time**: 3-8 seconds (depending on complexity)
- **Success Rate**: >95% for common topics

### OpenAI Integration âœ…
- **Models Supported**: GPT-3.5-turbo, GPT-4
- **Average Response Time**: 2-5 seconds
- **Quality Score**: High (human-readable summaries)
- **Cost Control**: Configurable limits and modes

---

## ğŸ”§ Advanced Configuration

### Environment Variables
```bash
# Required for working features
OPENAI_API_KEY=your_openai_api_key_here

# Cost control for multi-source agent
COST_MODE=BALANCED  # MINIMAL, BALANCED, COMPREHENSIVE
MAX_ARTICLES=3      # Maximum articles per query

# API configuration
API_PORT=5000
DEBUG_MODE=false
```

### Multi-Source Agent Configuration
```python
# In utils/multi_source_agent.py
COST_MODES = {
    'MINIMAL': {
        'max_articles': 1,
        'max_secondary_queries': 1,
        'enable_agents': True,
        'enable_openai': True
    },
    'BALANCED': {
        'max_articles': 3,
        'max_secondary_queries': 3,
        'enable_agents': True,
        'enable_openai': True
    },
    'COMPREHENSIVE': {
        'max_articles': 5,
        'max_secondary_queries': 5,
        'enable_agents': True,
        'enable_openai': True
    }
}
```

---

## ğŸš§ Future Development Roadmap

### Phase 1: Stabilize Under-Test Features ğŸ§ª
- [ ] **Complete BERT Intent Testing** - Finalize BERT model integration
- [ ] **Validate Semantic Search** - Test embedding-based article discovery
- [ ] **Local HF Model Support** - Enable offline BART/T5 summarization
- [ ] **Performance Optimization** - Improve response times and reliability

### Phase 2: Advanced Features
- [ ] **Multi-language Support** - Summarization in multiple languages
- [ ] **Document Upload** - Support for PDF, Word docs, and text files
- [ ] **Conversational Memory** - Multi-turn conversations with context
- [ ] **Custom Training** - Domain-specific model fine-tuning

### Phase 3: Enterprise Features
- [ ] **Real-time Collaboration** - Multiple users, shared workspaces
- [ ] **Advanced Analytics** - Usage patterns, model performance tracking
- [ ] **Plugin System** - Custom integrations and extensions
- [ ] **Mobile App** - React Native companion application

---

## ğŸ¤ Contributing

We welcome contributions! Focus areas:

### High Priority (Working Features) âœ…
1. **ğŸ”§ Bug Fixes** - Improve stability of working features
2. **ğŸ“Š Analytics** - Enhance monitoring and metrics
3. **ğŸ¨ UI/UX** - Streamlit interface improvements
4. **ğŸ“š Documentation** - Usage guides and examples

### Medium Priority (Under Test) ğŸ§ª
1. **ğŸ¤— HuggingFace Integration** - Complete local model support
2. **ğŸ” Semantic Search** - Finalize embedding-based search
3. **ğŸ§  BERT Testing** - Validate BERT intent classification
4. **ğŸ§ª Testing** - Expand test coverage for new features

### Development Setup
```bash
# Clone and setup
git clone https://github.com/your-username/SummarEaseAI.git
cd SummarEaseAI
pip install -r requirements.txt

# Test working features
python test_multi_source_fix.py
python quick_start.py
```

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **ğŸ¤— Hugging Face** for democratizing AI with open-source transformers
- **OpenAI** for GPT models and the OpenAI API
- **TensorFlow** team for the comprehensive ML framework
- **Streamlit** for the amazing web app framework
- **Wikipedia** for providing free access to human knowledge
- **LangChain** for powerful NLP orchestration tools

---

<div align="center">

**Built with â¤ï¸ using AI to make information more accessible**

### ğŸš€ **SummarEaseAI v2.0 - Multi-Source Intelligence Now Working!**

âœ… **Multi-Source Agent** | âœ… **Intent Classification** | âœ… **OpenAI Integration** | ğŸ§ª **Local AI Under Test**

â­ **Star this repository if you found it helpful!**

</div>
